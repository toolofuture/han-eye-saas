#!/usr/bin/env python3
"""
Train RL Agent with Reinforcement Learning from Demonstration (RLfD)

Usage:
    python scripts/train_rl_agent.py
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from app import create_app, db
from app.models import Analysis
from app.utils.rl_environment import ArtworkAuthEnv, BatchArtworkEnv
from app.utils.rl_agent import RLfDAgent, create_default_demonstrations
import numpy as np


def collect_training_data():
    """ì‚¬ìš©ì í”¼ë“œë°±ì´ ìˆëŠ” ë¶„ì„ ë°ì´í„° ìˆ˜ì§‘"""
    app = create_app()
    
    with app.app_context():
        # í”¼ë“œë°±ì´ ìˆëŠ” ë¶„ì„ë“¤
        analyses = Analysis.query.filter(
            Analysis.user_feedback.in_(['correct', 'incorrect'])
        ).all()
        
        if len(analyses) < 5:
            print(f"âš ï¸  í”¼ë“œë°± ë°ì´í„° ë¶€ì¡±: {len(analyses)}ê°œ (ìµœì†Œ 5ê°œ ê¶Œì¥)")
            print("   ì‚¬ìš©ì í”¼ë“œë°±ì„ ë” ìˆ˜ì§‘í•´ì£¼ì„¸ìš”!")
            return []
        
        image_paths = []
        ground_truths = []
        
        for analysis in analyses:
            if not os.path.exists(analysis.image_path):
                continue
            
            # Ground truth ê²°ì •
            if analysis.user_feedback == 'correct':
                ground_truth = analysis.is_authentic
            else:
                ground_truth = not analysis.is_authentic
            
            image_paths.append(analysis.image_path)
            ground_truths.append(ground_truth)
        
        print(f"âœ… ìˆ˜ì§‘ëœ í•™ìŠµ ë°ì´í„°: {len(image_paths)}ê°œ")
        print(f"   - ì§„í’ˆ: {sum(ground_truths)}ê°œ")
        print(f"   - ìœ„ì‘: {len(ground_truths) - sum(ground_truths)}ê°œ")
        
        return image_paths, ground_truths


def train_with_rlfd(image_paths=None, ground_truths=None, 
                    pretrain_epochs=100, train_timesteps=10000):
    """
    RLfD ë°©ì‹ìœ¼ë¡œ RL ì—ì´ì „íŠ¸ í•™ìŠµ
    
    1. Demonstration ìƒì„± (íœ´ë¦¬ìŠ¤í‹± íŒŒë¼ë¯¸í„°)
    2. Pre-training (Behavioral Cloning)
    3. RL Training (SAC)
    """
    
    print("\n" + "="*60)
    print("ğŸ¤– Reinforcement Learning from Demonstration (RLfD)")
    print("="*60 + "\n")
    
    # Step 1: í™˜ê²½ ìƒì„±
    print("ğŸ“¦ Step 1: í™˜ê²½ ìƒì„±...")
    
    if image_paths and len(image_paths) > 1:
        # ì—¬ëŸ¬ ì´ë¯¸ì§€ ë°°ì¹˜ í™˜ê²½
        env = BatchArtworkEnv(image_paths, ground_truths)
        print(f"   âœ… Batch environment with {len(image_paths)} images")
    elif image_paths and len(image_paths) == 1:
        # ë‹¨ì¼ ì´ë¯¸ì§€ í™˜ê²½
        env = ArtworkAuthEnv(image_paths[0], ground_truths[0] if ground_truths else None)
        print(f"   âœ… Single image environment")
    else:
        print("   âš ï¸  No training data available. Using demo mode.")
        # ë°ëª¨ìš© ë”ë¯¸ í™˜ê²½
        demo_image = os.path.join(os.path.dirname(__file__), '..', 'data', 'uploads', '.gitkeep')
        if not os.path.exists(demo_image):
            print("   âŒ No images available for training")
            return None
        env = ArtworkAuthEnv(demo_image, None)
    
    # Step 2: ì—ì´ì „íŠ¸ ìƒì„±
    print("\nğŸ§  Step 2: ì—ì´ì „íŠ¸ ìƒì„±...")
    agent = RLfDAgent(env)
    print("   âœ… RLfD Agent initialized")
    
    # Step 3: Demonstration ìƒì„±
    print("\nğŸ¯ Step 3: Demonstration ìƒì„±...")
    
    # 3-1: íœ´ë¦¬ìŠ¤í‹± íŒŒë¼ë¯¸í„°ì—ì„œ
    agent.load_demonstrations_from_heuristics()
    
    # 3-2: ì‚¬ìš©ì í”¼ë“œë°±ì—ì„œ
    if image_paths:
        app = create_app()
        with app.app_context():
            agent.load_demonstrations_from_feedback(db.session)
    
    print(f"   âœ… Total demonstrations: {len(agent.demonstrations)}")
    
    # Step 4: Pre-training
    print(f"\nğŸ“ Step 4: Pre-training (Behavioral Cloning)...")
    print(f"   Epochs: {pretrain_epochs}")
    
    try:
        agent.pretrain_with_demonstrations(epochs=pretrain_epochs)
    except Exception as e:
        print(f"   âš ï¸  Pre-training error: {e}")
        print("   Continuing with demonstration replay buffer only...")
    
    # Step 5: RL Training
    print(f"\nğŸš€ Step 5: Reinforcement Learning...")
    print(f"   Timesteps: {train_timesteps}")
    print(f"   Algorithm: SAC (Soft Actor-Critic)")
    
    try:
        agent.train(total_timesteps=train_timesteps)
    except ImportError:
        print("\nâš ï¸  stable-baselines3ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print("   ì„¤ì¹˜: pip install stable-baselines3 gymnasium")
        print("   ì§€ê¸ˆì€ demonstrationë§Œ ì €ì¥í•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"   âŒ Training error: {e}")
        return None
    
    # Step 6: í‰ê°€
    print("\nğŸ“Š Step 6: ëª¨ë¸ í‰ê°€...")
    try:
        metrics = agent.evaluate(n_eval_episodes=5)
        print(f"   Mean Reward: {metrics.get('mean_reward', 0):.2f}")
        print(f"   Std Reward: {metrics.get('std_reward', 0):.2f}")
    except:
        print("   âš ï¸  Evaluation skipped")
    
    # Step 7: ì €ì¥
    print("\nğŸ’¾ Step 7: ëª¨ë¸ ì €ì¥...")
    agent.save('models/rl_artwork_agent')
    
    print("\n" + "="*60)
    print("âœ… RLfD Training Complete!")
    print("="*60 + "\n")
    
    return agent


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Han.Eye - Reinforcement Learning from Demonstration  â•‘
â•‘  Inspired by Quantum Control RLfD Paper               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘
    print("ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    result = collect_training_data()
    
    if result:
        image_paths, ground_truths = result
    else:
        image_paths, ground_truths = None, None
    
    # RLfD í•™ìŠµ
    agent = train_with_rlfd(
        image_paths=image_paths,
        ground_truths=ground_truths,
        pretrain_epochs=100,
        train_timesteps=5000  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©
    )
    
    if agent:
        print("\nğŸ‰ í•™ìŠµ ì™„ë£Œ!")
        print("\nì‚¬ìš© ë°©ë²•:")
        print("1. ì›¹ì—ì„œ ì´ë¯¸ì§€ ë¶„ì„ ì‹œ ìë™ìœ¼ë¡œ RL ëª¨ë¸ ì‚¬ìš©")
        print("2. í”¼ë“œë°±ì„ ë” ì£¼ë©´ ëª¨ë¸ì´ ê³„ì† ê°œì„ ë©ë‹ˆë‹¤")
        print("3. python scripts/train_rl_agent.py ë¡œ ì¬í•™ìŠµ")
    else:
        print("\nâš ï¸  í•™ìŠµ ì‹¤íŒ¨")
        print("\ní•´ê²° ë°©ë²•:")
        print("1. pip install stable-baselines3 gymnasium ì„¤ì¹˜")
        print("2. ì‚¬ìš©ì í”¼ë“œë°± ë” ìˆ˜ì§‘ (ìµœì†Œ 5ê°œ)")
        print("3. ì´ë¯¸ì§€ ë°ì´í„° í™•ì¸")


if __name__ == '__main__':
    main()

